{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b56f102-a00a-4277-aa76-99e2237611ac",
   "metadata": {},
   "source": [
    "## instructionËØ≠ÊñôÂæÆË∞Éllama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5cf039-4b2c-431b-802f-949b075138dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T06:50:31.233788Z",
     "iopub.status.busy": "2024-12-13T06:50:31.233572Z",
     "iopub.status.idle": "2024-12-13T06:50:31.240860Z",
     "shell.execute_reply": "2024-12-13T06:50:31.240258Z",
     "shell.execute_reply.started": "2024-12-13T06:50:31.233766Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cd569-4025-47a1-b6cf-2c10c71af5c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ‰πãÂâçÁöÑÂæÆË∞É‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed66cb-e56f-46ce-a291-b86159ad01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import _utils\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = 'meta-llama/Meta-Llama-3-8B'\n",
    "lora_path = 'lora/llama3-8B-iepile-data2text-continue'\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b3ad3-a60c-466b-9aec-d94eebee9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509645e-c2f3-4a97-b43a-b9e4803b729e",
   "metadata": {},
   "source": [
    "### Áé∞Âú®‰ΩøÁî®ÁöÑÂæÆË∞É‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29cf09a-5b25-4ee5-a1d6-2d7529c99068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T06:50:33.886417Z",
     "iopub.status.busy": "2024-12-13T06:50:33.885185Z",
     "iopub.status.idle": "2024-12-13T06:50:41.673520Z",
     "shell.execute_reply": "2024-12-13T06:50:41.672499Z",
     "shell.execute_reply.started": "2024-12-13T06:50:33.886361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import _utils\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# Âä†ËΩΩLlamaÊ®°ÂûãÂíåTokenizer\n",
    "model_path = \"../model/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6\"\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# ÈÖçÁΩÆLoRAÂæÆË∞É\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # LoRAÂèÇÊï∞ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥\n",
    "    lora_alpha=16,  # LoRAÂèÇÊï∞ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥\n",
    "    lora_dropout=0.05,  # LoRAÂèÇÊï∞ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥\n",
    "    bias=\"none\",  # LoRAÂæÆË∞ÉÁöÑÂÅèÁΩÆÈÄâÈ°π\n",
    "    task_type=\"CAUSAL_LM\"  # ‰ªªÂä°Á±ªÂûãÔºåÈÄöÂ∏∏‰ΩøÁî®CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7623782-2584-432f-a9f5-6d485d318e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T06:50:45.225873Z",
     "iopub.status.busy": "2024-12-13T06:50:45.224312Z",
     "iopub.status.idle": "2024-12-13T06:50:47.122957Z",
     "shell.execute_reply": "2024-12-13T06:50:47.121888Z",
     "shell.execute_reply.started": "2024-12-13T06:50:45.225807Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "with open('../ft_data/train_data_v1.json', 'r', encoding='utf-8') as f:\n",
    "    train_data_raw = json.load(f)\n",
    "\n",
    "with open('../ft_data/val_data_v1.json', 'r', encoding='utf-8') as f:\n",
    "    val_data_raw = json.load(f)\n",
    "\n",
    "\n",
    "# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºöÂ∞Ü Instruction Âíå Input ÂêàÂπ∂‰∏∫ËæìÂÖ•ÔºåResponse ‰Ωú‰∏∫ËæìÂá∫\n",
    "def preprocess_data(data, tokenizer, max_length=512):\n",
    "    instructions = [item[\"Instruction\"] for item in data]\n",
    "    inputs = [item[\"Input\"] for item in data]\n",
    "    responses = [item[\"Response\"] for item in data]\n",
    "\n",
    "    # ÂêàÂπ∂ Instruction Âíå Input\n",
    "    inputs_combined = [f\"{instruction}\\n{input_text}\" for instruction, input_text in zip(instructions, inputs)]\n",
    "\n",
    "    # ‰ΩøÁî®Áªü‰∏ÄÁöÑmax_lengthÂ°´ÂÖÖÔºåÂπ∂Á°Æ‰øùinputsÂíålabelsÈïøÂ∫¶‰∏ÄËá¥\n",
    "    model_inputs = tokenizer(inputs_combined, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    labels = tokenizer(responses, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Á°Æ‰øù input_ids Âíå labels ÈïøÂ∫¶‰∏ÄËá¥\n",
    "    assert model_inputs[\"input_ids\"].shape[1] == labels.shape[1], f\"Length mismatch: {model_inputs['input_ids'].shape[1]} != {labels.shape[1]}\"\n",
    "\n",
    "    return {\"input_ids\": model_inputs[\"input_ids\"], \"labels\": labels}\n",
    "\n",
    "\n",
    "# Â∞ÜÊï∞ÊçÆËΩ¨Êç¢‰∏∫ÂêàÈÄÇÁöÑÊ†ºÂºè\n",
    "train_data_0 = [{\"Instruction\": item[\"instruction\"], \"Response\": item[\"output\"], \"Input\": item[\"rule\"]} for item in train_data_raw]\n",
    "val_data_0 = [{\"Instruction\": item[\"instruction\"], \"Response\": item[\"output\"], \"Input\": item[\"rule\"]} for item in val_data_raw]\n",
    "\n",
    "# Â∞ÜÊï∞ÊçÆËΩ¨Êç¢‰∏∫ÂêàÈÄÇÁöÑÊ†ºÂºè\n",
    "train_data = preprocess_data(train_data_0, tokenizer)\n",
    "val_data = preprocess_data(val_data_0, tokenizer)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cd3d5a-9d50-42ef-a74b-f809cbb2fd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T06:50:51.424103Z",
     "iopub.status.busy": "2024-12-13T06:50:51.422563Z",
     "iopub.status.idle": "2024-12-13T09:06:24.176848Z",
     "shell.execute_reply": "2024-12-13T09:06:24.175079Z",
     "shell.execute_reply.started": "2024-12-13T06:50:51.424036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_8053/3481787107.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11630' max='11630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11630/11630 2:15:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.607305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.684600</td>\n",
       "      <td>0.593674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.742600</td>\n",
       "      <td>0.567335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.842900</td>\n",
       "      <td>0.576224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.562700</td>\n",
       "      <td>0.567671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.916300</td>\n",
       "      <td>0.590891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563700</td>\n",
       "      <td>0.596283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.629527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.619426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.640178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11630, training_loss=0.5403298856672909, metrics={'train_runtime': 8132.4351, 'train_samples_per_second': 2.859, 'train_steps_per_second': 1.43, 'total_flos': 5.36275143622656e+17, 'train_loss': 0.5403298856672909, 'epoch': 10.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../lora\",  # ËæìÂá∫ÁõÆÂΩï\n",
    "    num_train_epochs=10,  # ËÆ≠ÁªÉËΩÆÊï∞\n",
    "    per_device_train_batch_size=2,  # ÊØè‰∏™ËÆæÂ§áÁöÑËÆ≠ÁªÉÊâπÈáèÂ§ßÂ∞è\n",
    "    per_device_eval_batch_size=2,  # ÊØè‰∏™ËÆæÂ§áÁöÑËØÑ‰º∞ÊâπÈáèÂ§ßÂ∞è\n",
    "    evaluation_strategy=\"epoch\",  # ÊØè‰∏™epochËøõË°åËØÑ‰º∞\n",
    "    save_strategy=\"epoch\",  # ÊØè‰∏™epoch‰øùÂ≠òÊ®°Âûã\n",
    "    logging_dir=\"../logs\",  # Êó•ÂøóÁõÆÂΩï\n",
    "    logging_steps=10,  # ÊØè10Ê≠•ËÆ∞ÂΩï‰∏ÄÊ¨°Êó•Âøó\n",
    "    save_steps=500,  # ÊØè500Ê≠•‰øùÂ≠ò‰∏ÄÊ¨°Ê®°Âûã\n",
    "    eval_steps=500,  # ÊØè500Ê≠•ËØÑ‰º∞‰∏ÄÊ¨°Ê®°Âûã\n",
    "    load_best_model_at_end=True,  # Âú®ËÆ≠ÁªÉÁªìÊùüÊó∂Âä†ËΩΩÊúÄ‰Ω≥Ê®°Âûã\n",
    "    # metric_for_best_model=\"accuracy\",  # Ê†πÊçÆÂáÜÁ°ÆÁéáÈÄâÊã©ÊúÄ‰Ω≥Ê®°Âûã\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcdbc59-ebf0-449d-a59d-cedee4ee64ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T09:22:49.067201Z",
     "iopub.status.busy": "2024-12-13T09:22:49.066380Z",
     "iopub.status.idle": "2024-12-13T09:22:49.177375Z",
     "shell.execute_reply": "2024-12-13T09:22:49.176563Z",
     "shell.execute_reply.started": "2024-12-13T09:22:49.067146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next is the answer:\n",
      " Âú®ÊüêÊ¨°Êµ∑‰∏äÊêúÊïë‰ªªÂä°‰∏≠ÔºåÊêúÊïë‰∏≠ÂøÉÊî∂Âà∞‰∫Ü‰∏ÄÊù°Á¥ßÊÄ•‰ø°ÊÅØÔºå‰∏ÄËâòËΩΩÊúâ200‰∫∫ÁöÑÂÆ¢ËΩÆÂú®ËøúÊ¥ãËà™Ë°å‰∏≠ÈÅáÂà∞‰∫ÜÊö¥È£éÈõ®ÔºåÂØºËá¥Ëàπ‰Ωì‰∏•ÈáçÂèóÊçüÔºåÊ∞¥ËøõÂÖ•ËàπËà±ÔºåËàπ‰∏äÁöÑ‰∫∫ÂëòÂ§Ñ‰∫éÊûÅÂ∫¶Âç±Èô©‰πã‰∏≠„ÄÇÂÆ¢ËΩÆÁõÆÂâçÂ∑≤Â§±ÂéªÂä®ÂäõÔºåÈöèÊó∂ÂèØËÉΩÊ≤âÊ≤°„ÄÇËÄÉËôëÂà∞Ê≠§Ê¨°Êµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂ÂØπ‰∫∫ÂëΩÂÆâÂÖ®ÁöÑ‰∏•ÈáçÂ®ÅËÉÅÔºåÊêúÊïë‰∏≠ÂøÉÈúÄË¶ÅÂà§Êñ≠Âπ∂‰∏äÊä•Ê≠§‰∫ã‰ª∂‰∏∫ÊúÄÈ´òÁ∫ßÂà´„ÄÇÊ≠§Ê¨°‰∫ã‰ª∂Â∫îÂΩíÁ±ª‰∏∫Âì™‰∏™Èô©ÊÉÖÁ≠âÁ∫ßÔºü\n",
      "Êµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖÂàÜÁ∫ßÔºöÊ†πÊçÆÂõΩÂÆ∂Á™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖ‰∏äÊä•ÁöÑÊúâÂÖ≥ËßÑÂÆöÔºåÂπ∂ÁªìÂêàÊµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂ÁöÑÁâπÁÇπÂèäÁ™ÅÂèë‰∫ã‰ª∂ÂØπ‰∫∫ÂëΩÂÆâÂÖ®„ÄÅÊµ∑Ê¥ãÁéØÂ¢ÉÁöÑÂç±ÂÆ≥Á®ãÂ∫¶Âíå‰∫ãÊÄÅÂèëÂ±ïË∂ãÂäøÔºåÂ∞ÜÊµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖ‰ø°ÊÅØÂàÜ‰∏∫ÁâπÂ§ß„ÄÅÈáçÂ§ß„ÄÅËæÉÂ§ß„ÄÅ‰∏ÄËà¨ÂõõÁ∫ß„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "# ËøõË°åÊé®ÁêÜ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = tokenizer(\"Âú®ÊüêÊ¨°Êµ∑‰∏äÊêúÊïë‰ªªÂä°‰∏≠ÔºåÊêúÊïë‰∏≠ÂøÉÊî∂Âà∞‰∫Ü‰∏ÄÊù°Á¥ßÊÄ•‰ø°ÊÅØÔºå‰∏ÄËâòËΩΩÊúâ200‰∫∫ÁöÑÂÆ¢ËΩÆÂú®ËøúÊ¥ãËà™Ë°å‰∏≠ÈÅáÂà∞‰∫ÜÊö¥È£éÈõ®ÔºåÂØºËá¥Ëàπ‰Ωì‰∏•ÈáçÂèóÊçüÔºåÊ∞¥ËøõÂÖ•ËàπËà±ÔºåËàπ‰∏äÁöÑ‰∫∫ÂëòÂ§Ñ‰∫éÊûÅÂ∫¶Âç±Èô©‰πã‰∏≠„ÄÇÂÆ¢ËΩÆÁõÆÂâçÂ∑≤Â§±ÂéªÂä®ÂäõÔºåÈöèÊó∂ÂèØËÉΩÊ≤âÊ≤°„ÄÇËÄÉËôëÂà∞Ê≠§Ê¨°Êµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂ÂØπ‰∫∫ÂëΩÂÆâÂÖ®ÁöÑ‰∏•ÈáçÂ®ÅËÉÅÔºåÊêúÊïë‰∏≠ÂøÉÈúÄË¶ÅÂà§Êñ≠Âπ∂‰∏äÊä•Ê≠§‰∫ã‰ª∂‰∏∫ÊúÄÈ´òÁ∫ßÂà´„ÄÇÊ≠§Ê¨°‰∫ã‰ª∂Â∫îÂΩíÁ±ª‰∏∫Âì™‰∏™Èô©ÊÉÖÁ≠âÁ∫ßÔºü\\nÊµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖÂàÜÁ∫ßÔºöÊ†πÊçÆÂõΩÂÆ∂Á™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖ‰∏äÊä•ÁöÑÊúâÂÖ≥ËßÑÂÆöÔºåÂπ∂ÁªìÂêàÊµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂ÁöÑÁâπÁÇπÂèäÁ™ÅÂèë‰∫ã‰ª∂ÂØπ‰∫∫ÂëΩÂÆâÂÖ®„ÄÅÊµ∑Ê¥ãÁéØÂ¢ÉÁöÑÂç±ÂÆ≥Á®ãÂ∫¶Âíå‰∫ãÊÄÅÂèëÂ±ïË∂ãÂäøÔºåÂ∞ÜÊµ∑‰∏äÁ™ÅÂèë‰∫ã‰ª∂Èô©ÊÉÖ‰ø°ÊÅØÂàÜ‰∏∫ÁâπÂ§ß„ÄÅÈáçÂ§ß„ÄÅËæÉÂ§ß„ÄÅ‰∏ÄËà¨ÂõõÁ∫ß„ÄÇ\", return_tensors=\"pt\").to(device)\n",
    "# inputs = tokenizer(\"Translate the following sentence to French.\\nGood evening!\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=512)\n",
    "print('Next is the answer:\\n', tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
