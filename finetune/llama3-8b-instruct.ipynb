{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333bbf8f-76e0-4b9f-8660-5d87ee83fbe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T01:56:19.563415Z",
     "iopub.status.busy": "2025-01-03T01:56:19.562714Z",
     "iopub.status.idle": "2025-01-03T01:56:19.571744Z",
     "shell.execute_reply": "2025-01-03T01:56:19.571134Z",
     "shell.execute_reply.started": "2025-01-03T01:56:19.563367Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373b69b3-37b4-47bb-9114-7e1308c43266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:06.126049Z",
     "iopub.status.busy": "2025-01-03T07:44:06.125660Z",
     "iopub.status.idle": "2025-01-03T07:44:10.749323Z",
     "shell.execute_reply": "2025-01-03T07:44:10.747992Z",
     "shell.execute_reply.started": "2025-01-03T07:44:06.126011Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 07:44:08,157 - modelscope - INFO - PyTorch version 2.5.1 Found.\n",
      "2025-01-03 07:44:08,161 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2025-01-03 07:44:08,304 - modelscope - INFO - Loading done! Current index file version is 1.9.5, with md5 3aab30afff949a3aeab78cecb6a273f9 and a total number of 945 components indexed\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "\n",
    "model_dir = snapshot_download('LLM-Research/Meta-Llama-3-8B-Instruct', cache_dir='/root/Logic-Bind-NL/model', revision='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08525320-d0b1-40e3-aae0-264352e83f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:14.011677Z",
     "iopub.status.busy": "2025-01-03T07:44:14.010820Z",
     "iopub.status.idle": "2025-01-03T07:44:14.529664Z",
     "shell.execute_reply": "2025-01-03T07:44:14.528827Z",
     "shell.execute_reply.started": "2025-01-03T07:44:14.011612Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f6e985-f376-49e2-8f4b-4885fa955289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:19.443486Z",
     "iopub.status.busy": "2025-01-03T07:44:19.442680Z",
     "iopub.status.idle": "2025-01-03T07:44:19.832126Z",
     "shell.execute_reply": "2025-01-03T07:44:19.831287Z",
     "shell.execute_reply.started": "2025-01-03T07:44:19.443430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|eot_id|>', 128009, 128009)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/root/Logic-Bind-NL/model/LLM-Research/Meta-Llama-3-8B-Instruct', use_fast=False, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token, tokenizer.pad_token_id, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5510f-c546-4ed5-bad6-6a018c6c13e4",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed50815f-ac4b-4750-92e5-2b3f5bbeac1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:23.028178Z",
     "iopub.status.busy": "2025-01-03T07:44:23.027304Z",
     "iopub.status.idle": "2025-01-03T07:44:23.040703Z",
     "shell.execute_reply": "2025-01-03T07:44:23.039659Z",
     "shell.execute_reply.started": "2025-01-03T07:44:23.028113Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 512    # Llama分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"<|start_header_id|>user<|end_header_id|>\\n\\n{example['instruction'] + example['input']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", add_special_tokens=False)\n",
    "    response = tokenizer(f\"{example['output']}<|eot_id|>\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  # 因为eos token也需要关注，所以补充为1\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:  # 如果数据超过最大长度限制则做截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc94508-ab94-4e93-b21a-4c9fdd4db792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:28.494716Z",
     "iopub.status.busy": "2025-01-03T07:44:28.493881Z",
     "iopub.status.idle": "2025-01-03T07:44:28.553738Z",
     "shell.execute_reply": "2025-01-03T07:44:28.552342Z",
     "shell.execute_reply.started": "2025-01-03T07:44:28.494667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '如果长江流域出现汛情、旱情及防汛抗旱动态，这些信息应该由哪个机构进行审核并发布？',\n",
       " 'output': '国家防总将对这些信息进行审核，并以统一发布的形式发布信息。',\n",
       " 'input': '信息发布：防汛抗旱的信息发布应当及时、准确、客观、全面。汛情、旱情及防汛抗旱动态等，由国家防总统一审核和发布；涉及水旱灾情的，由国家防办会同民政部审核和发布。信息发布形式主要包括投权发布、散发新闻稿、组织报道、接受记者采访、举行新闻发布会等。地方信息发布：重点汛区、灾区和发生局部汛情的地方，其汛情、旱情及防汛抗旱动态等信息，由各地防汛抗旱指挥机构审核和发布；涉及水旱灾情的，由各地防汛指挥部办公室会同民政部门审核和发布。'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将JSON文件转换为CSV文件\n",
    "df = pd.read_json('../ft_data/train_data_v3.json')\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fba0989-6a5e-4df1-956b-5667f5c019e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:30.816729Z",
     "iopub.status.busy": "2025-01-03T07:44:30.815963Z",
     "iopub.status.idle": "2025-01-03T07:44:32.557881Z",
     "shell.execute_reply": "2025-01-03T07:44:32.556856Z",
     "shell.execute_reply.started": "2025-01-03T07:44:30.816678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8327da-9f54-44f1-8ba7-1cb887d18111",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-01T12:42:38.815143Z",
     "iopub.status.busy": "2025-01-01T12:42:38.813612Z",
     "iopub.status.idle": "2025-01-01T12:42:38.830309Z",
     "shell.execute_reply": "2025-01-01T12:42:38.829499Z",
     "shell.execute_reply.started": "2025-01-01T12:42:38.815082Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "如果长江流域出现汛情、旱情及防汛抗旱动态，这些信息应该由哪个机构进行审核并发布？信息发布：防汛抗旱的信息发布应当及时、准确、客观、全面。汛情、旱情及防汛抗旱动态等，由国家防总统一审核和发布；涉及水旱灾情的，由国家防办会同民政部审核和发布。信息发布形式主要包括投权发布、散发新闻稿、组织报道、接受记者采访、举行新闻发布会等。地方信息发布：重点汛区、灾区和发生局部汛情的地方，其汛情、旱情及防汛抗旱动态等信息，由各地防汛抗旱指挥机构审核和发布；涉及水旱灾情的，由各地防汛指挥部办公室会同民政部门审核和发布。<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "国家防总将对这些信息进行审核，并以统一发布的形式发布信息。<|eot_id|><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_id[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c25f2-63bf-48ee-8afa-ceded17db516",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5720a8f-618c-49bb-a1dd-39adc02b861f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:38.706051Z",
     "iopub.status.busy": "2025-01-03T07:44:38.705645Z",
     "iopub.status.idle": "2025-01-03T07:44:45.034917Z",
     "shell.execute_reply": "2025-01-03T07:44:45.033189Z",
     "shell.execute_reply.started": "2025-01-03T07:44:38.706025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('/root/Logic-Bind-NL/model/LLM-Research/Meta-Llama-3-8B-Instruct', device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads() # 开启梯度checkpoint时，要执行该方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceea528-acc7-411d-a9e5-032adb520e60",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfdb88a3-0fe9-4988-bb05-c3d31ff44bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T13:13:05.628217Z",
     "iopub.status.busy": "2025-01-03T13:13:05.627715Z",
     "iopub.status.idle": "2025-01-03T13:13:09.943964Z",
     "shell.execute_reply": "2025-01-03T13:13:09.942992Z",
     "shell.execute_reply.started": "2025-01-03T13:13:05.628182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,  # 训练模式\n",
    "    r=8,  # Lora 秩\n",
    "    lora_alpha=32,  # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1  # Dropout 比例\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41d7260-46c0-4045-8aa6-de7643daddbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:44:50.020768Z",
     "iopub.status.busy": "2025-01-03T07:44:50.019924Z",
     "iopub.status.idle": "2025-01-03T07:44:50.891683Z",
     "shell.execute_reply": "2025-01-03T07:44:50.891064Z",
     "shell.execute_reply.started": "2025-01-03T07:44:50.020705Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58912c2-2651-44ba-bdda-89a002f1d842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:45:07.493958Z",
     "iopub.status.busy": "2025-01-03T07:45:07.493086Z",
     "iopub.status.idle": "2025-01-03T07:45:07.537598Z",
     "shell.execute_reply": "2025-01-03T07:45:07.536406Z",
     "shell.execute_reply.started": "2025-01-03T07:45:07.493895Z"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../lora/llama3-8B-instruct-v2\",\n",
    "    per_device_train_batch_size=4,  # batch size\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=10,  # 训练3个epoch\n",
    "    save_steps=100,\n",
    "    learning_rate=5e-5,  # 学习率\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33accee-2fd0-44fb-bf4e-5184893be38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T07:45:24.097029Z",
     "iopub.status.busy": "2025-01-03T07:45:24.096202Z",
     "iopub.status.idle": "2025-01-03T10:34:51.519865Z",
     "shell.execute_reply": "2025-01-03T10:34:51.518898Z",
     "shell.execute_reply.started": "2025-01-03T07:45:24.096976Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1760' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1760/1760 2:49:19, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.279500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.495600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.313700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.058600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.294100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.645500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.800100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.386600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.375700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.406000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.223700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.259400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.162700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.044200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.038100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('../lora/llama3-8B-instruct-v2.1/tokenizer_config.json',\n",
       " '../lora/llama3-8B-instruct-v2.1/special_tokens_map.json',\n",
       " '../lora/llama3-8B-instruct-v2.1/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "peft_model_id = \"../lora/llama3-8B-instruct-v2.1\"\n",
    "trainer.model.save_pretrained(peft_model_id)\n",
    "tokenizer.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32f637e-b44d-4869-ae72-3a2575c48d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T13:13:14.494441Z",
     "iopub.status.busy": "2025-01-03T13:13:14.493580Z",
     "iopub.status.idle": "2025-01-03T13:13:45.637892Z",
     "shell.execute_reply": "2025-01-03T13:13:45.636935Z",
     "shell.execute_reply.started": "2025-01-03T13:13:14.494384Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.77s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = '/root/Logic-Bind-NL/model/LLM-Research/Meta-Llama-3-8B-Instruct'\n",
    "lora_path = '../lora/llama3-8B-instruct-v2.1'\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a3745e-bc05-409e-9900-971d30950874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T13:13:57.493865Z",
     "iopub.status.busy": "2025-01-03T13:13:57.493156Z",
     "iopub.status.idle": "2025-01-03T13:14:32.640605Z",
     "shell.execute_reply": "2025-01-03T13:14:32.639773Z",
     "shell.execute_reply.started": "2025-01-03T13:13:57.493824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要向环保局通报。assistant\n",
      "\n",
      "在这次紧急情况中，应急办提出建立避难所的建议，并且指挥部批准了这个建议，因此需要向环保局通报建立避难所的安排。assistant\n",
      "\n",
      "需要向环保局通报。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"如果应急办提出建议，并且指挥部批准了，需要向哪个部门通报？\"\n",
    "messages = [\n",
    "    # {\"role\": \"system\", \"content\": \"现在你要扮演皇帝身边的女人--甄嬛\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')  # 将输入信息进行token化\n",
    "\n",
    "generated_ids = model.generate(  # 生成回答\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.1,\n",
    "    eos_token_id=tokenizer.encode('<|eot_id|>')[0],\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]  # 解码，输出本batch的第一个解码结果\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b81a994-566c-47ef-9164-31e2f88efc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T02:10:46.875764Z",
     "iopub.status.busy": "2025-01-03T02:10:46.875006Z",
     "iopub.status.idle": "2025-01-03T02:10:46.887245Z",
     "shell.execute_reply": "2025-01-03T02:10:46.886090Z",
     "shell.execute_reply.started": "2025-01-03T02:10:46.875710Z"
    }
   },
   "outputs": [],
   "source": [
    "def infer(prompt):\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"现在你要扮演皇帝身边的女人--甄嬛\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')  # 将输入信息进行token化\n",
    "    \n",
    "    generated_ids = model.generate(  # 生成回答\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.1,\n",
    "        repetition_penalty=1.1,\n",
    "        eos_token_id=tokenizer.encode('<|eot_id|>')[0],\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]  # 解码，输出本batch的第一个解码结果\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020ba33-012d-4997-bebf-efae18113a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T02:20:12.417811Z",
     "iopub.status.busy": "2025-01-03T02:20:12.417017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  0%|          | 1/499 [00:34<4:47:18, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  0%|          | 2/499 [01:09<4:46:17, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  1%|          | 3/499 [01:43<4:44:50, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  1%|          | 4/499 [02:18<4:45:17, 34.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  1%|          | 5/499 [02:52<4:44:37, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  1%|          | 6/499 [03:27<4:44:38, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  1%|▏         | 7/499 [04:02<4:43:56, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  2%|▏         | 8/499 [04:36<4:43:09, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  2%|▏         | 9/499 [05:11<4:42:40, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  2%|▏         | 10/499 [05:45<4:42:04, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  2%|▏         | 11/499 [06:20<4:42:11, 34.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  2%|▏         | 12/499 [06:55<4:41:54, 34.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  3%|▎         | 13/499 [07:30<4:40:39, 34.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  3%|▎         | 14/499 [08:04<4:39:21, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  3%|▎         | 15/499 [08:39<4:39:05, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  3%|▎         | 16/499 [09:14<4:39:13, 34.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  3%|▎         | 17/499 [09:48<4:39:08, 34.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  4%|▎         | 18/499 [10:23<4:38:38, 34.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  4%|▍         | 19/499 [10:58<4:37:17, 34.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  4%|▍         | 20/499 [11:32<4:36:00, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  4%|▍         | 21/499 [12:07<4:35:54, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  4%|▍         | 22/499 [12:41<4:35:26, 34.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  5%|▍         | 23/499 [13:16<4:34:24, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  5%|▍         | 24/499 [13:50<4:33:36, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  5%|▌         | 25/499 [14:25<4:33:13, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  5%|▌         | 26/499 [15:00<4:32:41, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  5%|▌         | 27/499 [15:34<4:32:29, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  6%|▌         | 28/499 [16:09<4:31:54, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  6%|▌         | 29/499 [16:43<4:30:38, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  6%|▌         | 30/499 [17:18<4:30:18, 34.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  6%|▌         | 31/499 [17:53<4:30:06, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  6%|▋         | 32/499 [18:27<4:29:40, 34.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  7%|▋         | 33/499 [19:02<4:28:56, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  7%|▋         | 34/499 [19:37<4:28:43, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  7%|▋         | 35/499 [20:11<4:27:48, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  7%|▋         | 36/499 [20:46<4:26:43, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  7%|▋         | 37/499 [21:20<4:25:39, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  8%|▊         | 38/499 [21:55<4:24:54, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  8%|▊         | 39/499 [22:29<4:23:56, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  8%|▊         | 40/499 [23:03<4:23:02, 34.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  8%|▊         | 41/499 [23:38<4:22:35, 34.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  8%|▊         | 42/499 [24:12<4:22:38, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  9%|▊         | 43/499 [24:47<4:22:51, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  9%|▉         | 44/499 [25:21<4:21:37, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  9%|▉         | 45/499 [25:56<4:20:29, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  9%|▉         | 46/499 [26:30<4:19:44, 34.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      "  9%|▉         | 47/499 [27:04<4:19:20, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 10%|▉         | 48/499 [27:39<4:18:47, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 10%|▉         | 49/499 [28:13<4:18:09, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 10%|█         | 50/499 [28:48<4:17:32, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 10%|█         | 51/499 [29:22<4:17:20, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 10%|█         | 52/499 [29:57<4:17:06, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 11%|█         | 53/499 [30:31<4:16:30, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 11%|█         | 54/499 [31:06<4:15:40, 34.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 11%|█         | 55/499 [31:40<4:15:13, 34.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 11%|█         | 56/499 [32:15<4:15:36, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 11%|█▏        | 57/499 [32:50<4:15:04, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 12%|█▏        | 58/499 [33:25<4:15:11, 34.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 12%|█▏        | 59/499 [33:59<4:13:45, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 12%|█▏        | 60/499 [34:34<4:12:45, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 12%|█▏        | 61/499 [35:08<4:11:40, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 12%|█▏        | 62/499 [35:43<4:11:24, 34.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 13%|█▎        | 63/499 [36:17<4:11:03, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 13%|█▎        | 64/499 [36:52<4:10:07, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 13%|█▎        | 65/499 [37:26<4:09:26, 34.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 13%|█▎        | 66/499 [38:01<4:09:36, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 13%|█▎        | 67/499 [38:36<4:09:50, 34.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 14%|█▎        | 68/499 [39:11<4:09:51, 34.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 14%|█▍        | 69/499 [39:45<4:08:53, 34.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 14%|█▍        | 70/499 [40:20<4:07:32, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 14%|█▍        | 71/499 [40:54<4:06:39, 34.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 14%|█▍        | 72/499 [41:29<4:06:24, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 15%|█▍        | 73/499 [42:03<4:05:26, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 15%|█▍        | 74/499 [42:38<4:05:18, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 15%|█▌        | 75/499 [43:13<4:04:24, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 15%|█▌        | 76/499 [43:47<4:03:56, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 15%|█▌        | 77/499 [44:22<4:03:20, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 16%|█▌        | 78/499 [44:56<4:01:59, 34.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 16%|█▌        | 79/499 [45:30<4:00:47, 34.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 16%|█▌        | 80/499 [46:05<4:01:10, 34.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 16%|█▌        | 81/499 [46:40<4:00:47, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 16%|█▋        | 82/499 [47:14<3:59:28, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 17%|█▋        | 83/499 [47:48<3:58:48, 34.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 17%|█▋        | 84/499 [48:23<3:58:33, 34.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 17%|█▋        | 85/499 [48:58<3:58:08, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 17%|█▋        | 86/499 [49:32<3:57:32, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 17%|█▋        | 87/499 [50:07<3:57:00, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 18%|█▊        | 88/499 [50:41<3:56:07, 34.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 18%|█▊        | 89/499 [51:16<3:56:10, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 18%|█▊        | 90/499 [51:50<3:55:55, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 18%|█▊        | 91/499 [52:26<3:56:53, 34.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 18%|█▊        | 92/499 [53:01<3:56:19, 34.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 19%|█▊        | 93/499 [53:36<3:55:57, 34.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 19%|█▉        | 94/499 [54:10<3:54:51, 34.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 19%|█▉        | 95/499 [54:45<3:53:46, 34.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 19%|█▉        | 96/499 [55:19<3:52:27, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 19%|█▉        | 97/499 [55:54<3:52:06, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 20%|█▉        | 98/499 [56:28<3:51:03, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 20%|█▉        | 99/499 [57:03<3:50:53, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 20%|██        | 100/499 [57:38<3:50:10, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 20%|██        | 101/499 [58:12<3:49:07, 34.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 20%|██        | 102/499 [58:46<3:48:09, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 21%|██        | 103/499 [59:20<3:46:59, 34.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 21%|██        | 104/499 [59:55<3:46:23, 34.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 21%|██        | 105/499 [1:00:29<3:45:40, 34.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 21%|██        | 106/499 [1:01:04<3:45:15, 34.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 21%|██▏       | 107/499 [1:01:38<3:45:14, 34.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 22%|██▏       | 108/499 [1:02:13<3:44:19, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 22%|██▏       | 109/499 [1:02:47<3:43:43, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 22%|██▏       | 110/499 [1:03:22<3:43:21, 34.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 22%|██▏       | 111/499 [1:03:56<3:43:32, 34.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 22%|██▏       | 112/499 [1:04:31<3:42:52, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 23%|██▎       | 113/499 [1:05:05<3:42:03, 34.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 23%|██▎       | 114/499 [1:05:40<3:40:59, 34.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 23%|██▎       | 115/499 [1:06:14<3:40:48, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 23%|██▎       | 116/499 [1:06:49<3:39:54, 34.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 23%|██▎       | 117/499 [1:07:23<3:38:37, 34.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 24%|██▎       | 118/499 [1:07:57<3:38:03, 34.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 24%|██▍       | 119/499 [1:08:32<3:37:54, 34.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 24%|██▍       | 120/499 [1:09:06<3:37:54, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 24%|██▍       | 121/499 [1:09:41<3:37:38, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 24%|██▍       | 122/499 [1:10:16<3:37:24, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 25%|██▍       | 123/499 [1:10:50<3:37:06, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 25%|██▍       | 124/499 [1:11:25<3:36:14, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 25%|██▌       | 125/499 [1:11:59<3:34:55, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 25%|██▌       | 126/499 [1:12:33<3:33:51, 34.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 25%|██▌       | 127/499 [1:13:08<3:33:15, 34.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 26%|██▌       | 128/499 [1:13:42<3:32:30, 34.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 26%|██▌       | 129/499 [1:14:16<3:31:36, 34.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 26%|██▌       | 130/499 [1:14:51<3:31:05, 34.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 26%|██▋       | 131/499 [1:15:25<3:31:10, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 26%|██▋       | 132/499 [1:16:00<3:30:55, 34.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 27%|██▋       | 133/499 [1:16:34<3:30:34, 34.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 27%|██▋       | 134/499 [1:17:09<3:30:26, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 27%|██▋       | 135/499 [1:17:44<3:30:00, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 27%|██▋       | 136/499 [1:18:19<3:29:42, 34.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 27%|██▋       | 137/499 [1:18:53<3:29:22, 34.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 28%|██▊       | 138/499 [1:19:28<3:28:59, 34.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 28%|██▊       | 139/499 [1:20:02<3:27:32, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 28%|██▊       | 140/499 [1:20:37<3:26:47, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 28%|██▊       | 141/499 [1:21:12<3:26:31, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 28%|██▊       | 142/499 [1:21:46<3:25:50, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 29%|██▊       | 143/499 [1:22:21<3:25:37, 34.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 29%|██▉       | 144/499 [1:22:56<3:25:10, 34.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 29%|██▉       | 145/499 [1:23:30<3:24:13, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 29%|██▉       | 146/499 [1:24:05<3:23:02, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 29%|██▉       | 147/499 [1:24:39<3:22:24, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 30%|██▉       | 148/499 [1:25:13<3:21:24, 34.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 30%|██▉       | 149/499 [1:25:48<3:20:46, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 30%|███       | 150/499 [1:26:22<3:20:19, 34.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 30%|███       | 151/499 [1:26:57<3:20:42, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 30%|███       | 152/499 [1:27:32<3:20:45, 34.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 31%|███       | 153/499 [1:28:07<3:19:54, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 31%|███       | 154/499 [1:28:41<3:19:30, 34.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 31%|███       | 155/499 [1:29:16<3:18:47, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 31%|███▏      | 156/499 [1:29:51<3:18:11, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 31%|███▏      | 157/499 [1:30:25<3:17:33, 34.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 32%|███▏      | 158/499 [1:31:00<3:17:22, 34.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 32%|███▏      | 159/499 [1:31:35<3:16:57, 34.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 32%|███▏      | 160/499 [1:32:10<3:16:07, 34.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 32%|███▏      | 161/499 [1:32:44<3:15:06, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 32%|███▏      | 162/499 [1:33:18<3:14:02, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 33%|███▎      | 163/499 [1:33:53<3:13:31, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 33%|███▎      | 164/499 [1:34:28<3:13:02, 34.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 33%|███▎      | 165/499 [1:35:03<3:13:10, 34.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 33%|███▎      | 166/499 [1:35:37<3:12:23, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 33%|███▎      | 167/499 [1:36:12<3:11:24, 34.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 34%|███▎      | 168/499 [1:36:46<3:11:04, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 34%|███▍      | 169/499 [1:37:21<3:09:49, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 34%|███▍      | 170/499 [1:37:55<3:09:14, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 34%|███▍      | 171/499 [1:38:30<3:08:40, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 34%|███▍      | 172/499 [1:39:04<3:08:16, 34.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 35%|███▍      | 173/499 [1:39:39<3:08:21, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 35%|███▍      | 174/499 [1:40:14<3:07:55, 34.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 35%|███▌      | 175/499 [1:40:49<3:07:14, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 35%|███▌      | 176/499 [1:41:23<3:06:20, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 35%|███▌      | 177/499 [1:41:58<3:05:50, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 36%|███▌      | 178/499 [1:42:32<3:05:23, 34.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 36%|███▌      | 179/499 [1:43:07<3:04:43, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 36%|███▌      | 180/499 [1:43:42<3:04:23, 34.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 36%|███▋      | 181/499 [1:44:16<3:03:32, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 36%|███▋      | 182/499 [1:44:51<3:02:47, 34.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 37%|███▋      | 183/499 [1:45:26<3:02:21, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 37%|███▋      | 184/499 [1:46:00<3:01:52, 34.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 37%|███▋      | 185/499 [1:46:35<3:01:33, 34.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 37%|███▋      | 186/499 [1:47:10<3:00:36, 34.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 37%|███▋      | 187/499 [1:47:44<3:00:05, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 38%|███▊      | 188/499 [1:48:18<2:58:46, 34.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 38%|███▊      | 189/499 [1:48:53<2:58:02, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 38%|███▊      | 190/499 [1:49:27<2:56:53, 34.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 38%|███▊      | 191/499 [1:50:01<2:56:40, 34.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 38%|███▊      | 192/499 [1:50:36<2:56:14, 34.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 39%|███▊      | 193/499 [1:51:11<2:55:57, 34.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 39%|███▉      | 194/499 [1:51:45<2:55:55, 34.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 39%|███▉      | 195/499 [1:52:20<2:55:27, 34.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 39%|███▉      | 196/499 [1:52:55<2:54:38, 34.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 39%|███▉      | 197/499 [1:53:29<2:53:27, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 40%|███▉      | 198/499 [1:54:03<2:52:38, 34.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 40%|███▉      | 199/499 [1:54:38<2:52:15, 34.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 40%|████      | 200/499 [1:55:12<2:52:08, 34.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 40%|████      | 201/499 [1:55:47<2:51:07, 34.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 40%|████      | 202/499 [1:56:21<2:50:14, 34.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 41%|████      | 203/499 [1:56:55<2:49:34, 34.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 41%|████      | 204/499 [1:57:29<2:48:45, 34.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n",
      " 41%|████      | 205/499 [1:58:04<2:48:05, 34.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128000 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('../ft_data/test_data_v2.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "ans = []\n",
    "for idx, input_ids in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    dicts = {\n",
    "        \"id\": idx,\n",
    "        \"output\": infer(input_ids[\"instruction\"])\n",
    "    }\n",
    "    ans.append(dicts)\n",
    "\n",
    "with open('../ft_data/test_output_v1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(ans, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63d56e0-63f2-43b9-819b-1b1f51770859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T02:17:22.456126Z",
     "iopub.status.busy": "2025-01-03T02:17:22.455270Z",
     "iopub.status.idle": "2025-01-03T02:17:22.463326Z",
     "shell.execute_reply": "2025-01-03T02:17:22.462543Z",
     "shell.execute_reply.started": "2025-01-03T02:17:22.456064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': '观测司负责监控和记录天体的位置、速度、距离和其他物理参数。assistant\\n\\n观测司负责监控和记录天体的位置、速度、距离和其他物理参数。'}, {'output': '该市应急救援指挥部将向国家安全生产监督管理总局发出请求，并且国家安全生产监督管理总局会提供所需的资源，包括医疗队伍和重型机械。assistant\\n\\n某市应急救援指挥部将向国家安全生产监督管理总局发出请求，并且国家安全生产监督管理总局会提供所需的资源，包括医疗队伍和重型机械。'}, {'output': '国家卫生健康委员会将负责组织应对甲型H1N1流感疫情。assistant\\n\\n国家卫生健康委员会将负责组织应对甲型H1N1流感疫情。'}, {'output': '对于任何高于一级的级别l，应急响应级别将被设置为一级。assistant\\n\\n如果当前应急响应级别为二级，则将降低该级别，并且新的应急响应级别为一级。'}, {'output': '在国际食品安全事件中，世界卫生组织（WHO）和联合国粮食及农业组织（FAO）将是指挥部的成员单位。assistant\\n\\n在国际食品安全事件中，世界卫生组织（WHO）和联合国粮食及农业组织（FAO）将是指挥部的成员单位。assistant\\n\\nWHO和FAO将组成指挥中心，负责响应国际食品安全事件。assistant\\n\\nWHO和FAO将建立一个共同的指挥中心，负责响应国际食品安全事件，并且该指挥中心将是全球范围内的唯一-authoritative机构。assistant\\n\\nWHO和FAO将建立一个共同的指挥中心，负责响应国际食品安全事件，并且该指挥中心将是全球范围内的唯一-authoritative机构，提供科学、技术和政策方面的指导。assistant\\n\\nWHO和FAO将建立一个共同的指挥中心，负责响应国际食品安全事件，并且该指挥中心将是全球范围内的唯一-authoritative机构，提供科学、技术和政策方面的指导，同时还将与相关方合作，包括政府、行业协会、消费者组织等。assistant\\n\\nWHO和FAO将建立一个共同的指挥中心，负责响应国际食品安全事件，并且该指挥中心将是全球范围内的唯一-authoritative机构，提供科学、技术和政策方面的指导，同时还将与相关方合作，包括政府、行业协会、消费者组织等，以确保食品安全。'}, {'output': '中国气象局负责发布沙尘暴红色预警。'}, {'output': '所有国家级急救中心必须是三级甲等医院，并且必须有心脏外科和重症监护床位。assistant\\n\\n所有国家级急救中心必须是三级甲等医院，并且必须有心脏外科和重症监护床位。'}, {'output': '当外国公司A向商务部报告数据泄露事件时，商务部将响应该事件。assistant\\n\\n商务部在外国公司A报告数据泄露事件后会响应该事件。assistant\\n\\n商务部会响应外国公司A的数据泄露事件。assistant\\n\\n商务部会对外国公司A进行支持和协助。assistant\\n\\n商务部会与外国公司A一起解决数据泄露问题。assistant\\n\\n商务部会采取预防措施来保护外国公司A的数据。assistant\\n\\n商务部会与外国公司A合作进行数据安全评估。assistant\\n\\n商务部会与外国公司A一起进行紧急响应。assistant\\n\\n商务部会与外国公司A合作进行安全清理。assistant\\n\\n商务部会与外国公司A一起进行安全改进。'}, {'output': '国家级矿山救援基地A作为煤矿，需要储备通风机和泄压设备。assistant\\n\\n国家级矿山救援基地A必须要有通风机和泄压设备。assistant\\n\\n国家级矿山救援基地A负责储备通风机和泄压设备。assistant\\n\\n国家级矿山救援基地A的责任包括储备通风机和泄压设备。assistant\\n\\n国家级矿山救援基地A负责保管通风机和泄压设备。'}, {'output': '将通知市政府。assistant\\n\\n在应急办提出建议并指挥部批准后，将通知市政府。'}]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
